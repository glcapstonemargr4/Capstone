{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"VGG16_model.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"bRSgwHDPNMuq"},"source":["![alt text](https://drive.google.com/uc?export=view&id=1UXScsVx_Wni_JuDdB8LeTnM6jsPfIwkW)"]},{"cell_type":"markdown","metadata":{"id":"dyce86qlNMu0"},"source":["## Model Building for Pneumonia Detection"]},{"cell_type":"markdown","metadata":{"id":"b1tqdxoaNMu1"},"source":["#### import libraries"]},{"cell_type":"code","metadata":{"id":"u_uCKOdXNMu2"},"source":["import os\n","import csv\n","import cv2\n","import keras\n","import pydicom\n","import numpy as np # linear algebra\n","np.random.seed(42)\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import tensorflow as tf\n","tf.random.set_seed(42)\n","import random as random\n","from sklearn import metrics\n","from sklearn import ensemble\n","from datetime import datetime\n","from tensorflow.keras import Sequential\n","from keras.optimizers import Adam\n","from keras.utils import Sequence\n","from skimage.transform import resize\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Concatenate, UpSampling2D,Conv2D\n","from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization,GlobalMaxPool2D\n","from tensorflow.keras.applications.vgg16 import VGG16,preprocess_input\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, average_precision_score\n","from sklearn.metrics import roc_auc_score, auc, plot_confusion_matrix, plot_roc_curve, roc_curve"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"07D8qp0uNMu3"},"source":["### Files Directories"]},{"cell_type":"code","metadata":{"id":"IYKxqNg4NMu4","outputId":"eff0b8de-ecf9-4fe2-861c-61b1502ffebc"},"source":["# Input data files are available in the\n","\n","dataDir = 'C:/Anaconda/GreatLearning/6. Capstone Project/'\n","trainDataDir = 'stage_2_train_images'\n","testDataDir = 'stage_2_test_images'\n","\n","## first 5 records\n","train_labels = pd.read_csv(dataDir+'stage_2_train_labels.csv')\n","train_labels=train_labels.fillna(0)\n","train_labels.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>patientId</th>\n","      <th>x</th>\n","      <th>y</th>\n","      <th>width</th>\n","      <th>height</th>\n","      <th>Target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0004cfab-14fd-4e49-80ba-63a80b6bddd6</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>00313ee0-9eaa-42f4-b0ab-c148ed3241cd</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>00322d4d-1c29-4943-afc9-b6754be640eb</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>003d8fa0-6bf1-40ed-b54c-ac657f8495c5</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>00436515-870c-4b36-a041-de91049b9ab4</td>\n","      <td>264.0</td>\n","      <td>152.0</td>\n","      <td>213.0</td>\n","      <td>379.0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                              patientId      x      y  width  height  Target\n","0  0004cfab-14fd-4e49-80ba-63a80b6bddd6    0.0    0.0    0.0     0.0       0\n","1  00313ee0-9eaa-42f4-b0ab-c148ed3241cd    0.0    0.0    0.0     0.0       0\n","2  00322d4d-1c29-4943-afc9-b6754be640eb    0.0    0.0    0.0     0.0       0\n","3  003d8fa0-6bf1-40ed-b54c-ac657f8495c5    0.0    0.0    0.0     0.0       0\n","4  00436515-870c-4b36-a041-de91049b9ab4  264.0  152.0  213.0   379.0       1"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"1Ksd4C9ENMu6"},"source":["### Modelling with Convolutional Neural Network "]},{"cell_type":"markdown","metadata":{"id":"MivgnC0MNMu7"},"source":["### Identify those who have pneumonia"]},{"cell_type":"code","metadata":{"id":"HqqYzL0KNMu7"},"source":["opacity_locations = {}\n","# load table\n","with open(os.path.join(dataDir+'stage_2_train_labels.csv'), mode='r') as infile:\n","    # open reader\n","    reader = csv.reader(infile)\n","    # skip header\n","    next(reader, None)\n","    # loop through rows\n","    for rows in reader:\n","        # retrieve information\n","        #print(reader)\n","        filename = rows[0]\n","        #print(filename)\n","        location = rows[1:5]\n","        #print(location)\n","        pneumonia = rows[5]\n","        #print(pneumonia)\n","        # if row contains pneumonia add label to dictionary\n","        # which contains a list of pneumonia locations per filename\n","        if pneumonia == '1':\n","            # convert string to float to int\n","            location = [int(float(i)) for i in location]\n","            # save pneumonia location in dictionary\n","            if filename in opacity_locations:\n","                opacity_locations[filename].append(location)\n","            else:\n","                opacity_locations[filename] = [location]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jSj3FuBfNMu8","outputId":"ed88cd13-8c69-4004-99bd-2f7083f1245a"},"source":["len(opacity_locations)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["6012"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"kz_WlbGmNMu8"},"source":["## As the data available for training is large\n","- build a data generator class that can help in building the input data in batches to avoid overwhelming the system memory\n","- use keras sequence class to get the data generator"]},{"cell_type":"code","metadata":{"id":"yx1zSbaJNMu9"},"source":["## parameter\n","img_width = 224\n","img_height = 224\n","IMAGE_SIZE=224\n","kernel =3\n","num_of_classes =2\n","BATCH_SIZE = 32\n","SHUFFLE_BUFFER_SIZE=1000"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IFNMWA1LNMu-"},"source":["from keras.utils import Sequence\n","import cv2\n","import pydicom\n","from skimage.transform import resize\n","class generator(keras.utils.Sequence):\n","    \n","    def __init__(self, folder, filenames, opacity_locations=None, batch_size=32, image_size=IMAGE_SIZE, shuffle=True, augment=False, predict=False):\n","        self.folder = folder\n","        self.filenames = filenames\n","        self.opacity_locations = opacity_locations\n","        self.batch_size = batch_size\n","        self.image_size = image_size\n","        self.shuffle = shuffle\n","        self.augment = augment\n","        self.predict = predict\n","        self.on_epoch_end()\n","        \n","    def __load__(self, filename):\n","        # load dicom file as numpy array\n","        img = pydicom.dcmread(os.path.join(self.folder, filename)).pixel_array\n","        # create empty mask\n","        msk = np.zeros(img.shape)\n","        # get filename without extension\n","        filename = filename.split('.')[0]\n","        # if image contains lung opacity\n","        if filename in opacity_locations:\n","            # loop through opacity\n","            for location in opacity_locations[filename]:\n","                # add 1's at the location of the lung opacity\n","                x, y, w, h = location\n","                msk[y:y+h, x:x+w] = 1\n","        # if augment then horizontal flip half the time\n","        if self.augment and random.random() > 0.5:\n","            img = np.fliplr(img)\n","            msk = np.fliplr(msk)\n","        # resize both image and mask\n","        #img = resize(img, (self.image_size, self.image_size), mode='reflect')\n","        msk = resize(msk, (self.image_size, self.image_size), mode='reflect') > 0.5\n","        # add trailing channel dimension\n","        msk = np.expand_dims(msk, -1)\n","         #Converting Image from GrayScale to RGB \n","        if len(img.shape) != 3 or img.shape[2] != 3:\n","            img = np.stack((img,) * 3, -1)\n","            img = cv2.resize(img, dsize=(self.image_size, self.image_size), interpolation=cv2.INTER_CUBIC)\n","        return img, msk\n","    \n","    def __loadpredict__(self, filename):\n","        # load dicom file as numpy array\n","        img = pydicom.dcmread(os.path.join(self.folder, filename)).pixel_array\n","        # resize image\n","        #img = resize(img, (self.image_size, self.image_size), mode='reflect')\n","        #Converting Image from GrayScale to RGB \n","        if len(img.shape) != 3 or img.shape[2] != 3:\n","            img = np.stack((img,) * 3, -1)\n","            img = cv2.resize(img, dsize=(self.image_size, self.image_size), interpolation=cv2.INTER_CUBIC)\n","        return img\n","        \n","    def __getitem__(self, index):\n","        # select batch\n","        filenames = self.filenames[index*self.batch_size:(index+1)*self.batch_size]\n","        # predict mode: return images and filenames\n","        if self.predict:\n","            # load files\n","            imgs = [self.__loadpredict__(filename) for filename in filenames]\n","            # create numpy batch\n","            imgs = np.array(imgs)\n","            return imgs, filenames\n","        # train mode: return images and masks\n","        else:\n","            # load files\n","            items = [self.__load__(filename) for filename in filenames]\n","            # unzip images and masks\n","            imgs, msks = zip(*items)\n","            # create numpy batch\n","            imgs = np.array(imgs)\n","            msks = np.array(msks)\n","            return imgs, msks\n","        \n","    def on_epoch_end(self):\n","        if self.shuffle:\n","            random.shuffle(self.filenames)\n","        \n","    def __len__(self):\n","        if self.predict:\n","            # return everything\n","            return int(np.ceil(len(self.filenames) / self.batch_size))\n","        else:\n","            # return full batches only\n","            return int(len(self.filenames) / self.batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nQi5OHGPNMu_"},"source":["### Split into train and validation files"]},{"cell_type":"code","metadata":{"id":"CP4-28h-NMvB","outputId":"fca2fae3-3009-49f5-b4d4-924ea8bd564d"},"source":["dataDir = 'C:/Anaconda/GreatLearning/6. Capstone Project/'\n","trainDataDir = 'stage_2_train_images'\n","testDataDir = 'stage_2_test_images'\n","folder = dataDir+'/stage_2_train_images/'\n","filenames = os.listdir(folder)\n","np.random.shuffle(filenames)\n","# split into train and validation filenames\n","n_valid_samples = 2500\n","n_train_samples = len(filenames) - n_valid_samples\n","train_filenames = filenames[n_valid_samples:]\n","valid_filenames = filenames[:n_valid_samples]\n","print('n train samples', len(train_filenames))\n","print('n valid samples', len(valid_filenames))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["n train samples 24184\n","n valid samples 2500\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_a3rKr3GNMvE"},"source":["### Generate Train and Validation data"]},{"cell_type":"code","metadata":{"id":"2uFTNrxdNMvF"},"source":["train_gen = generator(folder, train_filenames,\n","                      opacity_locations, batch_size=BATCH_SIZE,\n","                      image_size=IMAGE_SIZE, shuffle=True,augment=False, predict=False)\n","valid_gen = generator(folder, valid_filenames, \n","                      opacity_locations, batch_size=BATCH_SIZE, \n","                      image_size=IMAGE_SIZE, shuffle=False, predict=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y3Yo98S2NMvG"},"source":["### Resnet50  Model\n","- Transfer Learning Techniques, ResNet50\n"]},{"cell_type":"code","metadata":{"id":"vNgg81dkNMvG"},"source":["from tensorflow.keras.applications.resnet50 import ResNet50\n","from tensorflow.keras.layers import Concatenate, UpSampling2D\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense,Flatten\n","\n","resnet50 = Sequential()\n","resnet50.add(ResNet50(input_shape= (img_width, img_height, 3), \n","                   include_top=False, \n","                   weights='imagenet'))\n","\n","resnet50.add(Dense(1024, activation='relu'))\n","resnet50.add(UpSampling2D())\n","resnet50.add(Dense(512, activation='relu'))\n","resnet50.add(UpSampling2D())\n","resnet50.add(Dense(256, activation='relu'))\n","resnet50.add(UpSampling2D())\n","resnet50.add(Dense(64, activation='relu'))\n","resnet50.add(UpSampling2D())\n","resnet50.add(Dense(8, activation='relu'))\n","resnet50.add(UpSampling2D())\n","resnet50.add(Dense(1, activation='sigmoid'))\n","resnet50.layers[0].trainable = False"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vZJxgm5NNMvG"},"source":["### Compiling and Optimizing Augmented Model"]},{"cell_type":"code","metadata":{"id":"8szFcjOMNMvH","outputId":"4ba14eca-6312-4214-b56a-e521714a9443"},"source":["#compiling and Optimizing Augmented Model\n","optimizer =Adam() #(lr=0.0001,decay =1e-5)\n","resnet50.compile(loss='binary_crossentropy', \n","              optimizer=optimizer, \n","              metrics=['accuracy'])\n","resnet50.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","resnet50 (Functional)        (None, 7, 7, 2048)        23587712  \n","_________________________________________________________________\n","dense (Dense)                (None, 7, 7, 1024)        2098176   \n","_________________________________________________________________\n","up_sampling2d (UpSampling2D) (None, 14, 14, 1024)      0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 14, 14, 512)       524800    \n","_________________________________________________________________\n","up_sampling2d_1 (UpSampling2 (None, 28, 28, 512)       0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 28, 28, 256)       131328    \n","_________________________________________________________________\n","up_sampling2d_2 (UpSampling2 (None, 56, 56, 256)       0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 56, 56, 64)        16448     \n","_________________________________________________________________\n","up_sampling2d_3 (UpSampling2 (None, 112, 112, 64)      0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 112, 112, 8)       520       \n","_________________________________________________________________\n","up_sampling2d_4 (UpSampling2 (None, 224, 224, 8)       0         \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 224, 224, 1)       9         \n","=================================================================\n","Total params: 26,358,993\n","Trainable params: 2,771,281\n","Non-trainable params: 23,587,712\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bIPGATpoNMvI"},"source":["### Performed fitting for the Augmented model with the training and Validation dataset"]},{"cell_type":"code","metadata":{"id":"FXj8nzkJNMvJ","outputId":"fda14792-f218-4af8-c1ad-0cb597c7c344"},"source":["# this cell may take several minutes to run\n","start = datetime.now()\n","resnet50.fit(train_gen,validation_data=valid_gen,epochs=2,steps_per_epoch =5)\n","end = datetime.now()\n","elapsed = end - start\n","print('..........Run Time .........')\n","print('Time to fit augmented model is:\\n {}'.format(elapsed))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/2\n","5/5 [==============================] - 278s 68s/step - loss: 0.4830 - accuracy: 0.7233 - val_loss: 0.2074 - val_accuracy: 0.9746\n","Epoch 2/2\n","5/5 [==============================] - 303s 75s/step - loss: 0.1294 - accuracy: 0.9836 - val_loss: 0.1305 - val_accuracy: 0.9746\n","..........Run Time .........\n","Time to fit augmented model is:\n"," 0:09:43.224537\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nsMYkFygNMvJ"},"source":["### RESNET50 Model Evaluation"]},{"cell_type":"code","metadata":{"id":"TlGUXzz6NMvK","outputId":"1420debf-0ede-4479-847a-3e08271841f0"},"source":["resnet50_ev = resnet50.evaluate(valid_gen)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["78/78 [==============================] - 301s 4s/step - loss: 0.1305 - accuracy: 0.9746\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ABya96lxNMvK"},"source":["## VGG16 Model\n","- Transfer Learning Techniques, VGG16"]},{"cell_type":"code","metadata":{"id":"AV_TntEbNMvK"},"source":["from tensorflow.keras.applications.vgg16 import VGG16,preprocess_input"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9wkRGZjMNMvL"},"source":["#VGG16\n","vgg16 = Sequential()\n","vgg16.add(VGG16(input_shape= (img_width, img_height, 3), \n","                    include_top=False, \n","                    weights='imagenet'))\n","vgg16.add(Dense(1024, activation='relu'))\n","vgg16.add(UpSampling2D())\n","vgg16.add(Dense(512, activation='relu'))\n","vgg16.add(UpSampling2D())\n","vgg16.add(Dense(256, activation='relu'))\n","vgg16.add(UpSampling2D())\n","vgg16.add(Dense(64, activation='relu'))\n","vgg16.add(UpSampling2D())\n","vgg16.add(Dense(8, activation='relu'))\n","vgg16.add(UpSampling2D())\n","vgg16.add(Dense(1, activation='sigmoid'))\n","# Say not to train first layer model. It is already trained\n","vgg16.layers[0].trainable = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qLPtjdCFNMvL","outputId":"89b8d04d-da71-46d2-d695-67a7413b34c2"},"source":["#compiling and Optimizing Augmented Model\n","optimizer =Adam() #(lr=0.0001,decay =1e-5)\n","vgg16.compile(loss='binary_crossentropy', \n","              optimizer=optimizer , metrics=['accuracy']\n","                   )\n","vgg16.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","vgg16 (Functional)           (None, 7, 7, 512)         14714688  \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 7, 7, 1024)        525312    \n","_________________________________________________________________\n","up_sampling2d_5 (UpSampling2 (None, 14, 14, 1024)      0         \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 14, 14, 512)       524800    \n","_________________________________________________________________\n","up_sampling2d_6 (UpSampling2 (None, 28, 28, 512)       0         \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 28, 28, 256)       131328    \n","_________________________________________________________________\n","up_sampling2d_7 (UpSampling2 (None, 56, 56, 256)       0         \n","_________________________________________________________________\n","dense_9 (Dense)              (None, 56, 56, 64)        16448     \n","_________________________________________________________________\n","up_sampling2d_8 (UpSampling2 (None, 112, 112, 64)      0         \n","_________________________________________________________________\n","dense_10 (Dense)             (None, 112, 112, 8)       520       \n","_________________________________________________________________\n","up_sampling2d_9 (UpSampling2 (None, 224, 224, 8)       0         \n","_________________________________________________________________\n","dense_11 (Dense)             (None, 224, 224, 1)       9         \n","=================================================================\n","Total params: 15,913,105\n","Trainable params: 1,198,417\n","Non-trainable params: 14,714,688\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5eAKF6MPNMvL","outputId":"5b60726d-c56d-409a-8d39-e1fa494ae443"},"source":["# this cell may take several minutes to run\n","start = datetime.now()\n","vgg16.fit(train_gen,validation_data=valid_gen,epochs=2,steps_per_epoch =5)\n","end = datetime.now()\n","elapsed = end - start\n","print('..........Run Time .........')\n","print('Time to fit augmented model is:\\n {}'.format(elapsed))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/2\n","5/5 [==============================] - 534s 131s/step - loss: 1.5970 - accuracy: 0.5846 - val_loss: 0.1751 - val_accuracy: 0.9466\n","Epoch 2/2\n","5/5 [==============================] - 531s 131s/step - loss: 0.1662 - accuracy: 0.9629 - val_loss: 0.3241 - val_accuracy: 0.8504\n","..........Run Time .........\n","Time to fit augmented model is:\n"," 0:17:46.553130\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"McBF2fPZNMvM"},"source":["### VGG16 Model Evaluation"]},{"cell_type":"code","metadata":{"id":"PxIEuR9NNMvM","outputId":"116f7998-c45f-40c8-882d-e8f382765000"},"source":["vgg16_ev = vgg16.evaluate(valid_gen)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["78/78 [==============================] - 492s 6s/step - loss: 0.3241 - accuracy: 0.8504\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PeHTYFjaNMvM"},"source":["## Compare the Model (ResNet50 Vs VGG16)"]},{"cell_type":"markdown","metadata":{"id":"miuaQNEpNMvN"},"source":["## Hyper parameter Tuning"]},{"cell_type":"markdown","metadata":{"id":"Ndh7JXMqNMvN"},"source":["**mean iou as a metric**"]},{"cell_type":"code","metadata":{"id":"VCSRP5-hNMvN"},"source":["# mean iou as a metric\n","def mean_iou(y_true, y_pred):\n","    y_pred = tf.round(y_pred)\n","    intersect = tf.reduce_sum(y_true * y_pred, axis=[1, 2, 3])\n","    union = tf.reduce_sum(y_true, axis=[1, 2, 3]) + tf.reduce_sum(y_pred, axis=[1, 2, 3])\n","    smooth = tf.ones(tf.shape(intersect))\n","    return tf.reduce_mean((intersect + smooth) / (union - intersect + smooth))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cNRNGIM6NMvN"},"source":["#### Call Backs (Earlystop, ModelCheckpoint)"]},{"cell_type":"code","metadata":{"id":"zLH9s-WVNMvO"},"source":["from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n","## Earlystopping\n","earlystop = EarlyStopping(monitor='val_loss', patience=3)\n","\n","## Model Check point\n","filepath= \"/kaggle/working/LOHPT-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n","checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min', save_weights_only = True)\n","\n","## Reduce learning rate when metric has stopped improving\n","reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, \n","                                   patience=2, verbose=1, mode='auto', \n","                                   min_delta=0.0001, cooldown=5, min_lr=0.0001)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GLasjCMCNMvP"},"source":["#### Compilation"]},{"cell_type":"code","metadata":{"id":"hONqvOiXNMvP"},"source":["#compiling and Optimizing Augmented Model\n","optimizer =Adam(lr=0.0001,decay =1e-5)\n","resnet50.compile(loss='binary_crossentropy', \n","              optimizer=optimizer, \n","              metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hmOg2wO8NMvQ"},"source":["### Fitting the model"]},{"cell_type":"code","metadata":{"id":"ajZarrwcNMvQ"},"source":["history = resnet50.fit(train_gen, epochs=5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O5Wma0V0NMvQ"},"source":["resnet50.save_weights('FINAL_RESNET50.hdf5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8q_HZg4BNMvR"},"source":["print('Below is the representation of variation of loss and mean_iou for training and validation data.')\n","plt.figure(figsize=(15,6))\n","plt.subplot(121)\n","plt.plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n","plt.plot(history.epoch, history.history[\"val_loss\"], label=\"Valid loss\")\n","plt.legend()\n","plt.subplot(122)\n","plt.plot(history.epoch, history.history[\"mean_iou\"], label=\"Train iou\")\n","plt.plot(history.epoch, history.history[\"val_mean_iou\"], label=\"Valid iou\")\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zdAn4Mp0NMvR"},"source":[""],"execution_count":null,"outputs":[]}]}